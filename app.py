# app.py
import streamlit as st
import clip
import torch
import numpy as np
import pandas as pd
from PIL import Image
from pathlib import Path

# --- C·∫§U H√åNH ---
DATA_PATH = Path("data") # Th∆∞ m·ª•c ch·ª©a c√°c file ƒë√£ xu·∫•t ra
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

st.set_page_config(page_title="AI Image Search", layout="wide")
st.title("üîé H·ªá th·ªëng t√¨m ki·∫øm ·∫£nh ƒëa ph∆∞∆°ng th·ª©c (CLIP)")

# --- LOAD MODEL & DATA (Cache ƒë·ªÉ kh√¥ng ph·∫£i load l·∫°i m·ªói l·∫ßn click) ---
@st.cache_resource
def load_model():
    model, preprocess = clip.load("ViT-B/32", device=DEVICE)
    return model, preprocess

@st.cache_data
def load_data():
    try:
        features = np.load(DATA_PATH / "features.npy")
        photo_ids = pd.read_csv(DATA_PATH / "photo_ids.csv")
        metadata = pd.read_csv(DATA_PATH / "photos_metadata.csv")
        return features, photo_ids, metadata
    except FileNotFoundError:
        st.error("Kh√¥ng t√¨m th·∫•y file d·ªØ li·ªáu! H√£y ch·∫°y preprocess.py tr∆∞·ªõc.")
        return None, None, None

model, preprocess = load_model()
features, photo_ids_df, metadata = load_data()

# --- H√ÄM T√åM KI·∫æM ---
def search(query_features, dataset_features, top_k=5):
    # T√≠nh Cosine Similarity: (1, 512) x (N, 512).T -> (1, N)
    similarity = (query_features @ dataset_features.T).squeeze(0)
    
    # L·∫•y top K indices c√≥ ƒëi·ªÉm cao nh·∫•t
    top_indices = similarity.argsort()[-top_k:][::-1]
    return top_indices, similarity[top_indices]

def display_results(indices, scores):
    cols = st.columns(len(indices))
    for i, idx in enumerate(indices):
        # L·∫•y photo_id t·ª´ index
        p_id = photo_ids_df.iloc[idx]['photo_id']
        
        # L·∫•y th√¥ng tin metadata
        info = metadata[metadata['photo_id'] == p_id].iloc[0]
        
        with cols[i]:
            st.image(info['photo_image_url'] + "?w=400", use_container_width=True)
            st.caption(f"Score: {scores[i]:.4f}")
            st.markdown(f"**Photographer:** [{info['photographer_first_name']}](https://unsplash.com/@{info['photographer_username']})")

# --- GIAO DI·ªÜN ---
if features is not None:
    tab1, tab2 = st.tabs(["üìù Text to Image", "üñºÔ∏è Image to Image"])

    # TAB 1: T√åM B·∫∞NG TEXT
    with tab1:
        text_query = st.text_input("Nh·∫≠p m√¥ t·∫£ ·∫£nh b·∫°n mu·ªën t√¨m (Ti·∫øng Anh):", "A dog playing in the park")
        if st.button("T√¨m ki·∫øm", key="btn_text"):
            with st.spinner("ƒêang t√¨m..."):
                # Encode text
                text_tokenized = clip.tokenize([text_query]).to(DEVICE)
                with torch.no_grad():
                    query_feature = model.encode_text(text_tokenized)
                    query_feature /= query_feature.norm(dim=-1, keepdim=True)
                    query_feature = query_feature.cpu().numpy()
                
                # Search
                indices, scores = search(query_feature, features, top_k=5)
                display_results(indices, scores)

    # TAB 2: T√åM B·∫∞NG ·∫¢NH
    with tab2:
        uploaded_file = st.file_uploader("T·∫£i l√™n m·ªôt b·ª©c ·∫£nh ƒë·ªÉ t√¨m ·∫£nh t∆∞∆°ng t·ª±", type=["jpg", "png", "jpeg"])
        if uploaded_file is not None:
            # Hi·ªÉn th·ªã ·∫£nh upload
            image = Image.open(uploaded_file)
            st.image(image, caption="·∫¢nh g·ªëc", width=300)
            
            if st.button("T√¨m ·∫£nh t∆∞∆°ng t·ª±", key="btn_img"):
                with st.spinner("ƒêang ph√¢n t√≠ch..."):
                    # Encode image
                    image_input = preprocess(image).unsqueeze(0).to(DEVICE)
                    with torch.no_grad():
                        query_feature = model.encode_image(image_input)
                        query_feature /= query_feature.norm(dim=-1, keepdim=True)
                        query_feature = query_feature.cpu().numpy()
                    
                    # Search
                    indices, scores = search(query_feature, features, top_k=5)
                    display_results(indices, scores)